/*******************************************************************
 *                                                                 *
 * Copyright IBM Corp. 2018                                        *
 *                                                                 *
 *******************************************************************/
package com.ibm.research.drl.dpt.spark.vulnerability;

import com.ibm.research.drl.dpt.generators.ItemSet;
import com.ibm.research.drl.dpt.generators.LayerGenerator;
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.apache.spark.sql.Column;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;

import scala.Tuple2;

import java.util.ArrayList;
import java.util.Collection;
import java.util.List;

import static org.apache.spark.sql.functions.*;


public class BruteWithDatasetWithoutPruning {
    private static final Logger logger = LogManager.getLogger(BruteWithDatasetWithoutPruning.class);
    private static final String AGGREGATED_COUNT_NAME = "____FICTIONAL___COLUMN___NAME___";

    public Collection<Tuple2<List<String>, Long>> findVulnerabilitiesWithoutPruning(Dataset<Row> original, Collection<String> excludedFields, int k) {
        final String[] columnNames = original.columns();
        final LayerGenerator generator = new LayerGenerator(columnNames.length);
        final Collection<Tuple2<List<String>, Long>> offendingCombinations = new ArrayList<>();

        final Dataset<Row> dataset = original.cache();

        while (generator.hasNext()) {
            List<String> itemSet = generateItemset(columnNames, generator.next());

            if (containsExcludedField(itemSet, excludedFields)) continue;

            logger.debug("Testing " + itemSet);

            long offendingRecords = countOffendingRecords(dataset, itemSet, k);

            if (offendingRecords > 0) {
                offendingCombinations.add(new Tuple2<>(itemSet, offendingRecords));
            }
        }

        return offendingCombinations;
    }

    private long countOffendingRecords(Dataset<Row> dataset, List<String> itemSet, int k) {
        Column[] selectionColumn = convertToSelectionColumns(itemSet);

        Row[] rows = (Row[]) dataset.groupBy(selectionColumn)
                .agg(count(lit(1L)).as(AGGREGATED_COUNT_NAME))
                .filter(col(AGGREGATED_COUNT_NAME).lt(k))
                .agg(sum(col(AGGREGATED_COUNT_NAME)).as(AGGREGATED_COUNT_NAME))
                .collect();

        Row actualRow = rows[0];

        int idx = actualRow.fieldIndex(AGGREGATED_COUNT_NAME);

        if (!actualRow.isNullAt(idx)) {
            return actualRow.getLong(idx);
        }

        return 0;
    }

    private Column[] convertToSelectionColumns(List<String> itemSet) {
        Column[] columnNames = new Column[itemSet.size()];

        for (int i = 0; i < columnNames.length; ++i) {
            columnNames[i] = col(itemSet.get(i));
        }

        return columnNames;
    }

    private boolean containsExcludedField(Collection<String> itemSet, Collection<String> excludedFields) {
        return itemSet.removeAll(excludedFields);
    }

    private List<String> generateItemset(String[] columnNames, ItemSet itemIDs) {
        List<String> itemNames = new ArrayList<>(itemIDs.size());

        for (int id : itemIDs.getItems()) {
            itemNames.add(columnNames[id]);
        }

        return itemNames;
    }
}
